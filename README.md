# ğŸ§ Prosody-Aware Real-Time Speech Translation

*ä¸­è‹±æ–‡å®æ—¶åŒå£°ä¼ è¯‘ç³»ç»Ÿ (å¸¦éŸµå¾‹æ˜ å°„)*

<p align="center">
  <img src="assets/logo.png" alt="Project Logo" width="200"/>
</p>

<p align="center">
  <b>âš¡ Low-latency | ğŸ™ Real-time Speech Recognition | ğŸŒ Englishâ†’Chinese Translation | ğŸ”Š Natural TTS with Prosody</b>
</p>

---

## ğŸ“¸ Screenshots & Demo

<p align="center">
  <img src="assets/voicemeeter.png" alt="System Screenshot" width="600"/>
</p>

<p align="center">
  <img src="assets/demo.gif" alt="Live Demo" width="600"/>
</p>

---

## ğŸš€ Introduction | é¡¹ç›®ç®€ä»‹

**Prosody-Aware Real-Time Speech Translation** is an **end-to-end live interpreter system** that combines:

* ğŸ¤ **ASR (Speech Recognition)** â†’ Captures English speech in real time
* ğŸŒ **MT (Machine Translation)** â†’ Translates into fluent Chinese text
* ğŸ”Š **TTS (Speech Synthesis)** â†’ Generates natural Mandarin speech with **prosody mapping** (è¯­é€Ÿ & åœé¡¿ä¿æŒ)

è¯¥ç³»ç»Ÿé€šè¿‡ **è™šæ‹ŸéŸ³é¢‘çº¿ (Voicemeeter)** ä¸ä»»æ„ä¼šè®®è½¯ä»¶æ— ç¼é›†æˆï¼Œå¯å¹¿æ³›åº”ç”¨äºï¼š

* å›½é™…ä¼šè®®åŒå£°ä¼ è¯‘
* åœ¨çº¿è¯¾ç¨‹/è¿œç¨‹æ•™è‚²
* è·¨å›½ä¼ä¸šä¼šè®®
* æ–°é—»/å­¦æœ¯ç›´æ’­

---

## ğŸ— Architecture | ç³»ç»Ÿæ¶æ„

```mermaid
flowchart LR
  A[Input: CABLE-A Output] --> B[VAD and Segmentation];
  B --> C[ASR: Whisper small.en];
  C --> D[Buffer and Sentence Assembler];
  D --> E[MT EN_to_ZH];
  E --> P[Prosody Mapper rate_and_pause];
  P --> T[TTS Engine Edge-TTS];
  T --> H[Output: Voicemeeter Input to EV or Meeting];
```

```mermaid
flowchart LR
  A[ğŸ¤ Input: CABLE-A Output] --> B[ğŸ” VAD & Segmentation];
  B --> C[ğŸ“ ASR: Whisper small.en];
  C --> D[ğŸ“¦ Buffer & Sentence Assembler];
  D --> E[ğŸŒ MT: EN â†’ ZH];
  E --> F[ğŸ¶ Prosody Mapper (è¯­é€Ÿ/åœé¡¿è°ƒæ•´)];
  F --> G[ğŸ”Š TTS Engine (Azure / Local)];
  G --> H[ğŸ§ Output: Voicemeeter Input â†’ Meeting Software];

```
---

## âš™ï¸ Installation | å®‰è£…

```bash
git clone https://github.com/yourname/prosody-tts-vm.git
cd prosody-tts-vm
pip install -r requirements.txt
```

Dependencies:

* `torch` + CUDA (optional, for faster ASR)
* `whisper`
* `sounddevice`
* `pyaudio`
* `requests` (Azure TTS)

---

## ğŸ¯ Usage | ä½¿ç”¨æ–¹æ³•

```bash
python prosody_tts_vm.py \
  --mode live \
  --device-name "CABLE-A Output" \
  --tts_device_name "Voicemeeter Input (VB-Audio Voicemeeter VAIO)" \
  --whisper small.en \
  --lead_ms 1200 \
  --voice zh-CN-YunxiNeural \
  --tts_rate_pct -15 \
  --keep_wav --wav_dir ./wav_logs
```

| å‚æ•°                  | è¯´æ˜                    |
| ------------------- | --------------------- |
| `--device-name`     | æ•è·ç³»ç»ŸéŸ³é¢‘è¾“å…¥è®¾å¤‡            |
| `--tts_device_name` | è¾“å‡ºç¿»è¯‘è¯­éŸ³çš„è®¾å¤‡             |
| `--whisper`         | é€‰æ‹© ASR æ¨¡å‹             |
| `--lead_ms`         | ç¿»è¯‘ç¼“å†²æ—¶é—´ï¼Œæ§åˆ¶å»¶è¿Ÿä¸å®Œæ•´åº¦       |
| `--tts_rate_pct`    | è°ƒèŠ‚è¯­é€Ÿï¼Œå¦‚ -15 è¡¨ç¤ºæ¯”æ­£å¸¸æ…¢ 15% |
| `--keep_wav`        | æ˜¯å¦ä¿å­˜åˆæˆè¯­éŸ³æ—¥å¿—            |
| `--wav_dir`         | ä¿å­˜ç›®å½•                  |

---

## ğŸ“Š Performance | æ€§èƒ½æŒ‡æ ‡

| Model       | Avg Latency | Translation Completeness | GPU      |
| ----------- | ----------- | ------------------------ | -------- |
| `tiny.en`   | \~0.8s      | Medium                   | Optional |
| `small.en`  | \~1.2s      | High                     | âœ…        |
| `medium.en` | \~2.5s      | Very High                | âœ…        |

---

## ğŸŒŸ Features | å·¥ç¨‹äº®ç‚¹

* **Real-time + Robust** â†’ Avoids missing sentences with **buffer + VAD**
* **Prosody Mapping** â†’ Keeps rhythm & speech style
* **Scalable** â†’ Replaceable ASR / MT / TTS backends
* **Debuggable** â†’ Logs original audio, ASR text, translations, and TTS output

---

## ğŸ“‚ Project Structure | é¡¹ç›®ç»“æ„

```
prosody_tts_vm/
â”œâ”€â”€ prosody_tts_vm.py     # Main program
â”œâ”€â”€ requirements.txt      # Dependencies
â”œâ”€â”€ /wav_logs             # Audio logs
â”œâ”€â”€ /assets               # Logo, screenshots, GIFs
â””â”€â”€ README.md             # Documentation
```

---

## ğŸ”® Roadmap | åç»­æ‰©å±•

* Multi-language support (ä¸­ â†” è‹±, æ—¥ â†” ä¸­, etc.)
* Real-time meeting summarization with LLM
* Adaptive prosody control for speaker style simulation
* Enhanced fault-tolerance & auto-reconnection



